{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790fe347-8563-4f92-8c5c-173bf49e8008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./flant5/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in ./flant5/lib/python3.9/site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in ./flant5/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in ./flant5/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in ./flant5/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in ./flant5/lib/python3.9/site-packages (from torch) (2023.12.1)\n",
      "Requirement already satisfied: jinja2 in ./flant5/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in ./flant5/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: filelock in ./flant5/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: numpy in ./flant5/lib/python3.9/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in ./flant5/lib/python3.9/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./flant5/lib/python3.9/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./flant5/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./flant5/lib/python3.9/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./flant5/lib/python3.9/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./flant5/lib/python3.9/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./flant5/lib/python3.9/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./flant5/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/arush/workspace/646proj/LaMP/data/flant5/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in ./flant5/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./flant5/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./flant5/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./flant5/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./flant5/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./flant5/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./flant5/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./flant5/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: filelock in ./flant5/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./flant5/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./flant5/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./flant5/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./flant5/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./flant5/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./flant5/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./flant5/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./flant5/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/arush/workspace/646proj/LaMP/data/flant5/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arush/workspace/646proj/LaMP/data/flant5/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "!pip3 install transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import requests\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12cfb7e-3283-45ae-b7e8-a7d8278c3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/arush/workspace/646proj/LaMP/data/sampled_categorization_20.json\", \"r\") as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5856e725-0990-47aa-a9f7-1d13e741f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e986334-e27b-4d8b-b6c8-abaa72933800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e989ba0a704540d0aaca6457b32d6518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "llm_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xl\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07c8dde-effb-4a1d-ba69-2298a2831218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bb6b7e2c6b4dbd908f4dabcb599799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/flan-t5-xl\"\n",
    "summarizer = pipeline(\"summarization\", model = model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b45d03-7a40-4a68-baa1-c65f5d9c92be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                          | 0/20 [00:00<?, ?it/s]Your max_length is set to 200, but your input_length is only 56. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "/Users/arush/workspace/646proj/LaMP/data/flant5/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 17/20 [02:15<00:10,  3.55s/it]Your max_length is set to 200, but your input_length is only 74. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [04:04<00:00, 12.25s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "golds = []\n",
    "\n",
    "for user in tqdm(json_data):\n",
    "    i += 1\n",
    "    corpus = []\n",
    "    categories = []\n",
    "    profile = user['profile']\n",
    "    query = user['input']\n",
    "\n",
    "    input_prompt = \"Your task is to answer the query based on user's relevant history interactions.\\nHere’s the query: {}\\n\".format(query)\n",
    "    past_interactions = []\n",
    "    all_categories = [\"women\", \"religion\", \"politics\", \"style & beauty\", \"entertainment\", \"culture & arts\", \"sports\", \"science & technology\", \n",
    "    \"travel\", \"business\", \"crime\", \"education\", \"healthy living\", \"parents\", \"food & drink\"]\n",
    "    news_with_categories = {str(i): [] for i in all_categories}  \n",
    "\n",
    "    for doc in profile:\n",
    "        corpus.append(doc['text'])\n",
    "        categories.append(doc['category'])\n",
    "\n",
    "    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5, score_function=util.dot_score)\n",
    "    hits = hits[0]\n",
    "    predictions = {}\n",
    "\n",
    "    for hit in hits:\n",
    "        category = str(categories[hit['corpus_id']]) \n",
    "        news_with_categories[category].append(corpus[hit['corpus_id']])\n",
    "\n",
    "    word_limit = 512\n",
    "    for key, value in news_with_categories.items():\n",
    "        all_news = \"\"\n",
    "        if value:\n",
    "            sentences_str = \" \".join(value)\n",
    "            words_so_far = len(all_news.split())\n",
    "            words_in_current = len(sentences_str.split())\n",
    "    \n",
    "            if words_so_far + words_in_current <= word_limit:\n",
    "                all_news += sentences_str + \" \"\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            final_result = \" \".join(all_news.split()[:word_limit])\n",
    "            input_prompt += \"News category given by the user for the following news: '{}' is '{}'\".format(summarizer(final_result)[0]['summary_text'], key) + \"\\n\"\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "    outputs = llm_model.generate(**inputs)\n",
    "    predictions[\"output\"] = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    predictions[\"id\"] = user[\"id\"]\n",
    "    golds.append(predictions)\n",
    "\n",
    "final_json = {}\n",
    "final_json[\"task\"] = \"LaMP_2\"\n",
    "final_json[\"golds\"] = golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0d8600-42e1-41ce-a6cf-38fa90b24a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred_summarized_profile_news_categorization.json\", \"w\") as f:\n",
    "    json.dump(final_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadfd25-dc2f-4098-9c89-838352916781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
